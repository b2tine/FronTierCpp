#!/bin/bash

#SBATCH --job-name=mpi_job_test-3d   # Job name
#SBATCH --ntasks=8                   # Number of MPI tasks (i.e. processes
#SBATCH --cpus-per-task=1            # Number of cores per MPI task
#SBATCH --nodes=1                    # Maximum number of nodes to be allocated
#SBATCH --output=mpi_test_%j.log     # Path to the standard output and error files relative to the working directory

DIR=$(pwd)

echo "Date              = $(date)"
echo "Hostname          = $(hostname -s)"
echo "Working Directory = $DIR"
echo ""
echo "Number of Nodes Allocated      = $SLURM_JOB_NUM_NODES"
echo "Number of Tasks Allocated      = $SLURM_NTASKS"
echo "Number of Cores/Task Allocated = $SLURM_CPUS_PER_TASK"

module load mvapich2/2.3.3-gcc-8.3.1
#export LD_LIBRARY_PATH="/opt/sundials/sundials-2.7.0-opt/lib:/opt/petsc/petsc-3.13.4-opt/lib:/usr/lib64:$LD_LIBRARY_PATH"
echo $LD_LIBRARY_PATH

#Need to use mpiexec when using mvapich
mpiexec -np 8 $DIR/parachute -d 3 -p 2 2 2 -i $DIR/input-brandon-VREMAN/in-C9-VnG-ball-VREMAN-v5 -o out-C9-VnG-ball-VREMAN-v5

